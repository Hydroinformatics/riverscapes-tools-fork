"""
Merges standard BRAT databases (.gpkg) of the SAME REGION/HUC (e.g. with different models - FIS Sensitivity Analysis).
    For each reach, all columns to to copy will be collected ("lined up") in the new db.
    Assumptions:
        all rows (reaches) in each source database are equal and parallel.
        all columns to copy exist in each source database
    Result:
        # of items in the new db = # of items in any one source db (should be the same)

You can edit the config with your database paths and desired columns and run this script.

Disclaimers:
    Script can only copy integer outputs; geometry columns will not be copied correctly.
    This script was partially generated by AI.

Evan Hackstadt
July 2025
"""

import os
import statistics
import sqlite3

# --- CONFIGURATION ---

# Paths to your source databases                               # SET THESE
source_dbs = {
    # 'path to db': 'shorthand label'
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/0-Standard-FIS/outputs/brat.gpkg': 'ST',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shift-SPlow-Left/outputs/brat.gpkg': 'LEspl',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shift-SPlow-Right/outputs/brat.gpkg': 'RTspl',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shift-SP2-Left/outputs/brat.gpkg': 'LEsp2',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shift-SP2-Right/outputs/brat.gpkg': 'RTsp2',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shift-Slope-Left/outputs/brat.gpkg': 'LEslo',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shift-Slope-Right/outputs/brat.gpkg': 'RTslo',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Scale-Veg-Compress/outputs/brat.gpkg': 'CPveg',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Scale-Veg-Stretch/outputs/brat.gpkg': 'STveg',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Scale-Comb-Compress/outputs/brat.gpkg': 'CPcomb',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Scale-Comb-Stretch/outputs/brat.gpkg': 'STcomb',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Scale-Both-Compress/outputs/brat.gpkg': 'CPboth',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Scale-Both-Stretch/outputs/brat.gpkg': 'STboth',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shape-Veg/outputs/brat.gpkg': 'CVveg',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shape-Comb/outputs/brat.gpkg': 'CVcomb',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shape-Both/outputs/brat.gpkg': 'CVboth'
}
# ReachIDs should be equal in all source dbs
# Shorthand label will be used in the columns of the merged db

# Name of the table to extract from in each source database
source_table = 'ReachAttributes'

# Columns to copy (must exist in all source tables)
columns_to_copy_once = [    # independent columns
    'ReachID',  # do not change
    'WatershedID'
]
columns_to_copy_each = [    # from each source db
    'oVC_EX',
    'oCC_EX'
]

# Name of the new database and table
new_db_name = 'brat-all-fis.db'
new_db_dir = '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/fis-runs-processed/'                        # SET THIS
new_table_name = 'CombinedOutputs'

# Useful supplemental tables.
stats_table = True      # summarizes mean, st.dev, etc. of each column for all reaches
adjustments_table = True    # summarizes the FIS adjustments made in each source db



# --- SCRIPT STARTS HERE ---

new_db_path = os.path.join(new_db_dir, new_db_name)

with sqlite3.connect(new_db_path) as conn:
    cur = conn.cursor()

    # Useful row and column lists and strings
    ind_cols = columns_to_copy_once
    ind_col_stmt = ', '.join(ind_cols)
    src_dep_col_stmt = ', '.join(columns_to_copy_each)

    new_dep_cols = []
    for label in source_dbs.values():
        for col in columns_to_copy_each:
            new_dep_cols.append(f"{col}_{label}")

    new_all_cols = ind_cols + new_dep_cols
    new_all_cols_stmt = ', '.join(new_all_cols)

    # Create main table
    cur.execute(f"DROP TABLE IF EXISTS {new_table_name}")
    cur.execute(f"CREATE TABLE {new_table_name} ({new_all_cols_stmt})")
    conn.commit()

    # Populate new db. Gather relevant data and store

    # First get independent col data once from first source db
    db = list(source_dbs.keys())[0]
    print(f"Querying independent data from {db}...")
    src_conn = sqlite3.connect(db)
    src_cur = src_conn.cursor()
    src_cur.execute(f"SELECT {ind_col_stmt} FROM {source_table}")
    ind_rows = src_cur.fetchall()
    data = [list(row) for row in ind_rows]  # convert from tuple

    # Now, for each source db, get data for all reaches and store
    for db, label in source_dbs.items():
        print(f"Now processing {db}...")
        src_conn = sqlite3.connect(db)
        src_cur = src_conn.cursor()
        src_cur.execute(f"SELECT {src_dep_col_stmt} FROM {source_table}")
        dep_rows = src_cur.fetchall()
        for i in range(len(data)):    # assuming db structures parallel
            data[i] += list(dep_rows[i])    # append this db's dep cols
        src_conn.close()
    # Insert stored data
    placeholders = ', '.join(['?'] * (len(data[0])))
    print(placeholders)
    insert_stmt = f"INSERT INTO {new_table_name} ({new_all_cols_stmt}) VALUES ({placeholders})"
    print(insert_stmt)
    cur.executemany(insert_stmt, data)

    conn.commit()
    print(f"Inserted {len(ind_rows)} rows of data for all columns")


    # —— Populate stats table if requested ——
    if stats_table:
        print(f"Processing all reaches into Stats table...")
        
        stat_cols = ["Mean", "St_Dev", "Min", "Max"]
        cur.execute("DROP TABLE IF EXISTS Stats")
        cur.execute(f"CREATE TABLE Stats (Label, {', '.join(stat_cols)})")
        
        results = {stat: [] for stat in stat_cols}    # Mean: [means for each col], ...
        # compute stats
        for col in new_dep_cols:
            cur.execute(f"SELECT AVG({col}), MIN({col}), MAX({col}) FROM {new_table_name}")
            mean_, min_, max_ = cur.fetchone()
            # store in dictionary
            results["Mean"].append(round(mean_, 3))
            results["Min"].append(round(min_, 2))
            results["Max"].append(round(max_, 2))

            # use python for st.dev
            cur.execute(f"SELECT {col} FROM {new_table_name}")
            values = [row[0] for row in cur.fetchall() if row[0] is not None]
            if len(values) > 1:
                stdev = round(statistics.stdev(values), 3)
            else:
                stdev = None
            results["St_Dev"].append(stdev)

        # insert a row for each dependent column (source data)
        # stats are columns
        placeholders = ', '.join(['?'] * (1 + len(stat_cols)))
        for i in range(len(new_dep_cols)):
            row = []
            row.append(new_dep_cols[i])     # label
            for stat in stat_cols:
                row.append(results[stat][i])
            cur.execute(f"INSERT INTO Stats VALUES ({placeholders})", row)
        
        conn.commit()
        print(f"Stats table populated successfully.")
        
        
    # ——— Populate adj table if requested
    if adjustments_table:
        print(f"Summarizing source databases into Adjustments Table...")
        
        adj_cols = ["Veg_Type", "Veg_Val", "Comb_Type", "Comb_SPlow_Val", "Comb_SP2_Val", "Comb_Slope_Val"]
        cur.execute("DROP TABLE IF EXISTS Adjustments")
        cur.execute(f"CREATE TABLE Adjustments (Label, {', '.join(adj_cols)})")
        
        adj_data = {label: {col: None for col in adj_cols} for label in new_dep_cols}   # oVC_EX_ST: [Veg_Type, Veg_Val, Comb_Type, ...], ...
        # get adjustment data from each source db
        for db in source_dbs:
            with sqlite3.connect(db) as src_conn:
                src_cur = src_conn.cursor()
                # know which labels correspond to this db
                db_shorthand = source_dbs[db]
                db_labels = [col for col in new_dep_cols if db_shorthand in col]
                # check for source FIS_Adjustments table
                src_cur.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='FIS_Adjustments'")
                fis_table = src_cur.fetchall()
                if fis_table == []:
                    print(f"FIS table not found for database {db}. Inserting NULLs...")
                    continue    # skip this db
                # assuming table exists, get data
                src_cur.execute(f"SELECT FIS, MF, Adj_Type, Adj_Value FROM FIS_Adjustments")
                db_fis_data = src_cur.fetchall()    # [(FIS, MF, Adj_Type, Adj_Value), (FIS, ...), ...]

                # extract FIS data and store it for the appropriate labels
                for row in db_fis_data:
                    if row[0] == "Vegetation FIS":
                        for label in db_labels:
                            if row[2] is not None:  # only store if non-Null Adj_Type
                                adj_data[label]["Veg_Type"] = row[2]
                                adj_data[label]["Veg_Val"] = row[3]
                    elif row[0] == "Combined FIS":
                        for label in db_labels:
                            if row[2] is not None:
                                adj_data[label]["Comb_Type"] = row[2]
                                if row[1] == "SPlow": adj_data[label]["Comb_SPlow_Val"] = row[3]
                                if row[1] == "SP2": adj_data[label]["Comb_SP2_Val"] = row[3]
                                if row[1] == "Slope": adj_data[label]["Comb_Slope_Val"] = row[3]
            
        # now insert all data for all dbs
        # rows are source data labels (main table dep columns)
        # we will have redundancy but the label rows will match the stats table and main table cols
        placeholders = ', '.join(['?'] * (1 + len(adj_cols)))
        for label, data in adj_data.items():
            insert_stmt = f"INSERT INTO Adjustments VALUES ({placeholders})"
            row = [label] + [data.get(val) for val in adj_cols]
            cur.execute(insert_stmt, row)

        conn.commit()
        print(f"Adjustments table populated successfully.")


print("Merging complete! Data is in", new_db_path)