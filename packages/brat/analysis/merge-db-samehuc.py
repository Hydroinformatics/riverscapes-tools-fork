"""
Merges standard BRAT databases (.gpkg) of the SAME REGION/HUC (e.g. with different models - FIS Sensitivity Analysis).
    For each reach, all columns to to copy will be collected ("lined up") in the new db.
    Assumptions:
        all rows (reaches) in each source database are equal and parallel.
        all columns to copy exist in each source database
    Result:
        # of items in the new db = # of items in any one source db (should be the same)

You can edit the config with your database paths and desired columns and run this script.

Disclaimers:
    Script can only copy integer outputs; geometry columns will not be copied correctly.
    This script was partially generated by AI.

Evan Hackstadt
July 2025
"""

import sqlite3
import os
import statistics

# --- CONFIGURATION ---

# Paths to your source databases                               # SET THESE
source_dbs = {
    # 'path to db': 'shorthand label'
}
# ReachIDs should be equal in all source dbs
# Shorthand label will be used in the columns of the merged db

# Name of the table to extract from in each source database
source_table = 'ReachAttributes'

# Columns to copy (must exist in all source tables)
columns_to_copy_once = [    # independent columns
    'ReachID',
    'WatershedID'
]
columns_to_copy_each = [    # from each source db
    'oVC_EX',
    'oCC_EX'
]

# Name of the new database and table
new_db = 'brat-all-fis.db'
new_db_path = ''                                            # SET THIS
new_table_name = 'CombinedOutputs'

# Add a table to the database summarizing the mean, st.dev, etc. of each column for all reaches
stats_table = True



# --- SCRIPT STARTS HERE ---

# Create the new database and table
new_db_path = os.path.join(new_db_path, new_db)
conn = sqlite3.connect(new_db_path)
cur = conn.cursor()

# Drop tables if they exists (for repeatable runs)
cur.execute(f"DROP TABLE IF EXISTS {new_table_name}")
if stats_table: cur.execute("DROP TABLE IF EXISTS Stats")

# Build CREATE TABLE statement
ind_cols = columns_to_copy_once
dep_cols = []
ind_col_stmt = ''
dep_col_stmt = ''
for col in columns_to_copy_once:
    dep_col_stmt += f", {col} REAL"
for col in columns_to_copy_each:
    for label in source_dbs.values():
        dep_cols.append(f"{col}_{label}")
        dep_col_stmt += f", {col}_{label} REAL"

# Create table(s)
cur.execute(f"CREATE TABLE {new_table_name} ({ind_col_stmt}, {dep_col_stmt})")
if stats_table:
    cur.execute(f"CREATE TABLE Stats (Statistic, {dep_col_stmt})")
conn.commit()

# For first source database, copy data to independent columns
db = source_dbs[0]
print(f"Adding independent data from {db}...")
src_conn = sqlite3.connect(db)
src_cur = src_conn.cursor()
src_cur.execute(f"SELECT {ind_col_stmt} FROM {source_table}")
rows = src_cur.fetchall()
# Prepare insert statement
placeholders = ', '.join(['?']*len(rows))
insert_stmt = f"INSERT INTO {new_table_name} ({ind_col_stmt}) VALUES ({placeholders})"
cur.executemany(insert_stmt, rows)
src_conn.close()
print(f"Inserted {len(rows)} rows for columns {columns_to_copy_once}")

# For each source database, copy data to dependent columns
for db, label in source_dbs.items():
    print(f"Processing {db}...")
    src_conn = sqlite3.connect(db)
    src_cur = src_conn.cursor()
    src_cur.execute(f"SELECT {', '.join(columns_to_copy_each)} FROM {source_table}")
    rows = src_cur.fetchall()
    # Prepare insert statement
    db_col_stmt = ''
    for col in columns_to_copy_each:
        db_col_stmt += f", {col}_{label} REAL"
    placeholders = ', '.join(['?'] * len(rows))
    insert_stmt = f"INSERT INTO {new_table_name} ({db_col_stmt}) VALUES ({placeholders})"
    data = rows
    cur.executemany(insert_stmt, data)
    src_conn.close()
    print(f"Inserted {len(rows)} rows from {db} for columns {columns_to_copy_each}")

conn.commit()

# Populate stats table if requested
if stats_table:
    print(f"Processing all reaches into Stats table...")
    stats = ["Average", "Min", "Max", "StandardDeviation"]
    stats_results = {stat: [] for stat in stats}    # to hold results for each stat

    # compute stats
    for col in dep_cols:
        cur.execute(f"SELECT AVG({col}), MIN({col}), MAX({col}) FROM {new_table_name}")
        avg, min_, max_ = cur.fetchone()
        # store in dictionary
        stats_results["Average"].append(avg)
        stats_results["Min"].append(min_)
        stats_results["Max"].append(max_)

        # use python for st.dev
        cur.execute(f"SELECT {col} FROM {new_table_name}")
        values = [row[0] for row in cur.fetchall()]
        stdev = statistics.stdev(values)
        stats_results["StandardDeviation"].append(stdev)

    # insert a row for each stat
    for stat in stats:
        row = [stat] + stats_results[stat]
        placeholders = ', '.join(['?'] * len(row))
        cur.executemany(f"INSERT INTO Stats VALUES ({placeholders})", row)
    
    conn.commit()


conn.close()
print("Merging complete! Data is in", new_db_path)