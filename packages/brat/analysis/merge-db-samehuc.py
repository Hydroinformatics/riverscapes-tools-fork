"""
Merges standard BRAT databases (.gpkg) of the SAME REGION/HUC (e.g. with different models - FIS Sensitivity Analysis).
    For each reach, all columns to to copy will be collected ("lined up") in the new db.
    Assumptions:
        all rows (reaches) in each source database are equal and parallel.
        all columns to copy exist in each source database
    Result:
        # of items in the new db = # of items in any one source db (should be the same)

You can edit the config with your database paths and desired columns and run this script.

Disclaimers:
    Script can only copy integer outputs; geometry columns will not be copied correctly.
    This script was partially generated by AI.

Evan Hackstadt
July 2025
"""

# TODO:
#   - Broken. Schema is good, but vals are NULL.
#   - pivot stats table such that stats are columns?


import sqlite3
import os
import statistics

# --- CONFIGURATION ---

# Paths to your source databases                               # SET THESE
source_dbs = {
    # 'path to db': 'shorthand label'
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/0-Standard-FIS/outputs/brat.gpkg':
        'Standard',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/Lower-Siletz-River-1710020407/Shape-Both/outputs/brat.gpkg':
        'P_Bt'
}
# ReachIDs should be equal in all source dbs
# Shorthand label will be used in the columns of the merged db

# Name of the table to extract from in each source database
source_table = 'ReachAttributes'

# Columns to copy (must exist in all source tables)
columns_to_copy_once = [    # independent columns
    'ReachID',
    'WatershedID'
]
columns_to_copy_each = [    # from each source db
    'oVC_EX',
    'oCC_EX'
]

# Name of the new database and table
new_db = 'brat-all-fis.db'
new_db_path = '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/fis-runs/fis-runs-processed/'                        # SET THIS
new_table_name = 'CombinedOutputs'

# Add a table to the database summarizing the mean, st.dev, etc. of each column for all reaches
stats_table = True



# --- SCRIPT STARTS HERE ---

# Create the new database and table
new_db_path = os.path.join(new_db_path, new_db)
conn = sqlite3.connect(new_db_path)
cur = conn.cursor()

# Drop tables if they exists (for repeatable runs)
cur.execute(f"DROP TABLE IF EXISTS {new_table_name}")
if stats_table: cur.execute("DROP TABLE IF EXISTS Stats")

# Build CREATE TABLE statement
ind_cols = columns_to_copy_once
dep_cols = []
# ind_col_stmt = []
# dep_col_stmt = []
for col in columns_to_copy_each:
    for label in source_dbs.values():
        dep_cols.append(f"{col}_{label}")

ind_col_stmt = ', '.join(ind_cols)
dep_col_stmt = ', '.join(dep_cols)

# Create table(s)
cur.execute(f"CREATE TABLE {new_table_name} ({ind_col_stmt}, {dep_col_stmt})")
if stats_table:
    cur.execute(f"CREATE TABLE Stats (Statistic, {dep_col_stmt})")
conn.commit()

# For first source database, copy data to independent columns (one time)
db = list(source_dbs.keys())[0]
print(f"Adding independent data from {db}...")
src_conn = sqlite3.connect(db)
src_cur = src_conn.cursor()
src_cur.execute(f"SELECT {ind_col_stmt} FROM {source_table}")
rows = src_cur.fetchall()
# Prepare insert statement
placeholders = ', '.join(['?'] * len(ind_cols))
insert_stmt = f"INSERT INTO {new_table_name} ({ind_col_stmt}) VALUES ({placeholders})"
cur.executemany(insert_stmt, rows)
src_conn.close()
print(f"Inserted {len(rows)} rows for columns {columns_to_copy_once}")

# For each source database, copy data to dependent columns (iterative)
for db, label in source_dbs.items():
    print(f"Processing {db}...")
    src_conn = sqlite3.connect(db)
    src_cur = src_conn.cursor()
    src_cur.execute(f"SELECT {', '.join(columns_to_copy_each)} FROM {source_table}")
    rows = src_cur.fetchall()
    # Prepare insert statement
    db_cols = []
    for col in columns_to_copy_each:
        db_cols.append(f"{col}_{label}")
    placeholders = ', '.join(['?'] * len(db_cols))
    insert_stmt = f"INSERT INTO {new_table_name} ({', '.join(db_cols)}) VALUES ({placeholders})"
    cur.executemany(insert_stmt, rows)
    src_conn.close()
    print(f"Inserted {len(rows)} rows from {db} for columns {columns_to_copy_each}")

conn.commit()

# Populate stats table if requested
if stats_table:
    print(f"Processing all reaches into Stats table...")
    stats = ["Average", "Min", "Max", "StandardDeviation"]
    stats_results = {stat: [] for stat in stats}    # to hold results for each stat

    # compute stats
    for col in dep_cols:
        cur.execute(f"SELECT AVG({col}), MIN({col}), MAX({col}) FROM {new_table_name}")
        avg, min_, max_ = cur.fetchone()
        # store in dictionary
        stats_results["Average"].append(round(avg, 3))
        stats_results["Min"].append(round(min_, 2))
        stats_results["Max"].append(round(max_, 2))

        # use python for st.dev
        cur.execute(f"SELECT {col} FROM {new_table_name}")
        values = [row[0] for row in cur.fetchall() if row[0] is not None]
        if len(values) > 1:
            stdev = round(statistics.stdev(values), 3)
        else:
            stdev = None
        stats_results["StandardDeviation"].append(stdev)

    # insert a row for each stat
    for stat in stats:
        row = [stat] + stats_results[stat]
        placeholders = ', '.join(['?'] * (len(dep_cols) + 1))
        cur.execute(f"INSERT INTO Stats VALUES ({placeholders})", row)
    
    conn.commit()


conn.close()
print("Merging complete! Data is in", new_db_path)