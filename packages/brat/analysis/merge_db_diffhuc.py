"""
Merges standard BRAT databases (.gpkg) of the SAME MODEL, on DIFFERENT REGIONS.
    All entries (rows) of each database will be collected ("stacked") together in the new db.
    Assumptions:
        all rows (reaches) in each source database are unique.
        all columns to copy exist in each source database.
    Result:
        # of items in the new db = sum of items in all source dbs

You can edit the config with your database paths and desired columns and run this script.

Disclaimers:
    Script can only copy integer outputs; geometry columns will not be copied correctly.
    This script was partially generated by AI.

Evan Hackstadt
July 2025
"""

# TODO:
# - connect lookup tables to correct features in the new db


import os
import sqlite3

# --- CONFIGURATION ---

# List your source databases
source_dbs = [
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/public-runs/Lower-Siletz-River-1710020407/BRAT-LSR-2025/outputs/brat.gpkg',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/public-runs/Middle-Siletz-River-1710020405/BRAT-MSR-2025/outputs/brat.gpkg',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/public-runs/Upper-Siletz-River-1710020404/BRAT-USR-2025/outputs/brat.gpkg',
    '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/public-runs/Rock-Creek-1710020406/BRAT-RC-2025/outputs/brat.gpkg'
]

# Name of the table to extract from in each source database
source_table = 'ReachAttributes'

# Columns to copy (must exist in all source tables)
columns_to_copy = [     # will be cast to REAL
    'WatershedID',
    'iGeo_Slope', 'iGeo_Len',
    'iVeg100EX', 'iVeg_30EX',
    'iVeg100HPE', 'iVeg_30HPE',
    'iHyd_Qlow', 'iHyd_Q2',
    'iHyd_SPlow', 'iHyd_SP2',
    'oVC_EX', 'oVC_HPE',
    'oCC_EX', 'oCC_HPE',
    'mCC_EX_CT', 'mCC_HPE_CT',
    'LimitationID', 'RiskID', 'OpportunityID',
    'mCC_HisDep'
    ]  # <-- edit as needed

# Lookup tables to copy (should correspond to the columns above; should be identical in all source databases)
lookup_tables_to_copy = [
    'Watersheds',
    'DamLimitations',
    'DamRisks',
    'DamOpportunities',
    'DamCapacities'
]

# New database output directory, name, and main table name
new_db_dir = '/Users/evan/Code/OSU-EB3-REU/sqlBRAT/public-runs/public-runs-processed'
new_db_name = 'brat-all-siletz-custom.db'
new_table = 'CombinedOutputs'

# Options - column to track the source database? summary table?
track_source = True
stats_table = True



# --- SCRIPT STARTS HERE ---

# Create the new database and table
new_db_path = os.path.join(new_db_dir, new_db_name)
with sqlite3.connect(new_db_path) as conn:
    cur = conn.cursor()

    # Drop tables if they exists (for repeatable runs)
    cur.execute(f"DROP TABLE IF EXISTS {new_table}")
    for table in lookup_tables_to_copy:
        cur.execute(f"DROP TABLE IF EXISTS {table}")

    # First copy lookup tables â€” only need to do this from one source database since identical
    if lookup_tables_to_copy:
        print("Copying lookup tables...")
        src_conn = sqlite3.connect(source_dbs[0])
        src_cur = src_conn.cursor()
        
        for table in lookup_tables_to_copy:
            print(f"Copying {table}...")
            src_cur.execute(f"SELECT * FROM {table}")
            rows = src_cur.fetchall()
            col_names = [description[0] for description in src_cur.description]
            
            # Create the table in the new database
            col_defs = ', '.join([f"{col} TEXT" for col in col_names])  # Assuming TEXT for simplicity
            create_stmt = f"CREATE TABLE {table} ({col_defs})"
            cur.execute(create_stmt)
            
            # Insert data into the new table
            placeholders = ', '.join(['?'] * len(col_names))
            insert_stmt = f"INSERT INTO {table} ({', '.join(col_names)}) VALUES ({placeholders})"
            cur.executemany(insert_stmt, rows)
            
            print(f"Inserted {len(rows)} rows into {table}")
        
        src_conn.close()


    # Build CREATE TABLE statement
    col_defs = ', '.join([f"{col} REAL" for col in columns_to_copy])  # Cast all to REAL
    if track_source:
        col_defs += ', SourceDB TEXT'
    create_stmt = f"CREATE TABLE {new_table} ({col_defs})"
    cur.execute(create_stmt)
    conn.commit()

    # For each source database, copy the data
    for db in source_dbs:
        print(f"Processing {db}...")
        src_conn = sqlite3.connect(db)
        src_cur = src_conn.cursor()
        col_list = ', '.join(columns_to_copy)
        src_cur.execute(f"SELECT {col_list} FROM {source_table}")
        rows = src_cur.fetchall()
        # Prepare insert statement
        placeholders = ', '.join(['?'] * len(columns_to_copy))
        if track_source:
            insert_stmt = f"INSERT INTO {new_table} ({col_list}, SourceDB) VALUES ({placeholders}, ?)"
            data = [row + (db,) for row in rows]
        else:
            insert_stmt = f"INSERT INTO {new_table} ({col_list}) VALUES ({placeholders})"
            data = rows
        cur.executemany(insert_stmt, data)
        src_conn.close()
        print(f"Inserted {len(rows)} rows from {db}")

    conn.commit()

    # Optional Stats table to summarize results by HUC

    if stats_table:
        print("Creating Stats table to summarize results by HUC...")

        custom_huc_names = {        # customize this to your WatershedIDs
            1710020407: 'Lower Siletz',
            1710020405: 'Middle Siletz',
            1710020404: 'Upper Siletz',
            1710020406: 'Rock Creek'
        }

        categories = ['None', 'Rare', 'Occasional', 'Frequent', 'Pervasive']

        oCC_cutoffs = [
            {'label': categories[0], 'upper': 0},
            {'label': categories[1], 'lower': 0, 'upper': 1},
            {'label': categories[2], 'lower': 1, 'upper': 5},
            {'label': categories[3], 'lower': 5, 'upper': 15},
            {'label': categories[4], 'lower': 15}
        ]

        cols_to_summarize = {   # col_name: operation
            "mCC_EX_CT": "SUM",
            "oVC_EX": "AVG",
            "oCC_EX": "AVG",
            "oCC_HPE": "AVG"
        }

        stat_cols = ["WatershedID", "HUC_Name"]
        stat_cols += [f"{op}_{col}" for col, op in cols_to_summarize.items()]
        stat_cols += ["None_Percent", "Rare_Percent", "Occasional_Percent", "Frequent_Percent", "Pervasive_Percent"]

        # create table
        cur.execute(f"DROP TABLE IF EXISTS Stats")
        print(f"{', '.join(stat_cols)}")
        cur.execute(f"CREATE TABLE Stats ({', '.join(stat_cols)})")

        # figure out what hucs we are working with
        cur.execute(f"SELECT DISTINCT WatershedID FROM {new_table}")
        hucs = [row[0] for row in cur.fetchall()]   # convert to list of ints
        print(f"Found {len(hucs)} distinct HUCs in db.")

        # each huc will be a row
        for huc in hucs:
            print(f"Processing HUC {huc}...")

            huc_name = custom_huc_names[int(huc)] if int(huc) in custom_huc_names.keys() else None
            print(f"Custom HUC name: {huc_name}")
            row_data = [huc, huc_name]

            # Process cols_to_summarize for this huc
            for col, operation in cols_to_summarize.items():
                cur.execute(f"SELECT {operation}({col}), WatershedID FROM {new_table} WHERE WatershedID = {huc}")
                result = [val[0] for val in cur.fetchall()]     # don't store WatershedID
                result = round(result[0], 2)    # convert from list [float] to rounded float
                row_data.append(result)
                print(f"Selected {operation}({col}) = {result} for HUC {huc} in {new_table}")
            
            # Now calculate % of each capacity categories
            # Code adapted from Riverscapes' brat_report.py
            # % of reaches in category = total length of reaches with oCC_EX in bounds / total length of all reaches
            for cat in oCC_cutoffs:
                label = cat['label']
                lower = cat['lower'] if 'lower' in cat else None
                upper = cat['upper'] if 'upper' in cat else None
                extra_clauses = []
                extra_args = []
                if lower is not None:
                    extra_clauses.append('r.oCC_EX > ?')
                    extra_args.append(lower)
                if upper is not None:
                    extra_clauses.append('r.oCC_EX <= ?')
                    extra_args.append(upper)

                # Build the WHERE clause
                where_sql = 'r.WatershedID = ?'
                if extra_clauses:
                    where_sql += ' AND ' + ' AND '.join(extra_clauses)

                # Use JOIN for denominator clarity
                cur.execute(f"""
                    SELECT (0.1 * SUM(r.iGeo_Len) / t.total_length) AS Percent
                    FROM {new_table} r
                    JOIN (
                        SELECT SUM(iGeo_Len) / 1000 AS total_length
                        FROM {new_table}
                        WHERE WatershedID = ?
                    ) t ON 1=1
                    WHERE {where_sql}
                """, [huc, huc] + extra_args)
                row = cur.fetchone()
                percent = round(row[0], 2) if row and row[0] is not None else None
                row_data.append(percent)
                print(f"Calculated {percent}% of reaches in {cat['label']} category")
            
            # insert data
            placeholders = ', '.join(['?'] * len(row_data))
            insert_stmt = f"INSERT INTO Stats ({', '.join(stat_cols)}) VALUES({placeholders})"
            cur.execute(insert_stmt, row_data)
            conn.commit()   
        
        print("Stats table complete.")


print("Merging complete! Data is in", new_db_path)
